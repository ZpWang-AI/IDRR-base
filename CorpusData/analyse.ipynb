{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PDTB 2.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Comparison', 156),\n",
       " ('Comparison.Concession', 6),\n",
       " ('Comparison.Concession.Contra-expectation', 182),\n",
       " ('Comparison.Concession.Expectation', 31),\n",
       " ('Comparison.Contrast', 1222),\n",
       " ('Comparison.Contrast.Juxtaposition', 700),\n",
       " ('Comparison.Contrast.Opposition', 141),\n",
       " ('Comparison.Pragmatic concession', 1),\n",
       " ('Comparison.Pragmatic contrast', 2),\n",
       " ('Contingency', 1),\n",
       " ('Contingency.Cause', 1),\n",
       " ('Contingency.Cause.Reason', 2434),\n",
       " ('Contingency.Cause.Result', 1678),\n",
       " ('Contingency.Condition.Hypothetical', 1),\n",
       " ('Contingency.Pragmatic cause.Justification', 69),\n",
       " ('Contingency.Pragmatic condition.Relevance', 1),\n",
       " ('Expansion', 91),\n",
       " ('Expansion.Alternative', 3),\n",
       " ('Expansion.Alternative.Chosen alternative', 167),\n",
       " ('Expansion.Alternative.Conjunctive', 10),\n",
       " ('Expansion.Conjunction', 3440),\n",
       " ('Expansion.Exception', 1),\n",
       " ('Expansion.Instantiation', 1395),\n",
       " ('Expansion.List', 386),\n",
       " ('Expansion.Restatement', 212),\n",
       " ('Expansion.Restatement.Equivalence', 273),\n",
       " ('Expansion.Restatement.Generalization', 190),\n",
       " ('Expansion.Restatement.Specification', 2433),\n",
       " ('Temporal', 1),\n",
       " ('Temporal.Asynchronous.Precedence', 499),\n",
       " ('Temporal.Asynchronous.Succession', 151),\n",
       " ('Temporal.Synchrony', 175)]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "usecols = [\n",
    "    'Relation', 'Section', \n",
    "    'Arg1_RawText', 'Arg2_RawText', \n",
    "    'Conn1', 'Conn2',\n",
    "    'ConnHeadSemClass1', 'ConnHeadSemClass2',\n",
    "    'Conn2SemClass1', 'Conn2SemClass2'\n",
    "]\n",
    "df = pd.read_csv(\n",
    "    r'D:\\0--data\\projects\\04.01-IDRR\\IDRR-base\\CorpusData\\PDTB2\\pdtb2.csv',\n",
    "    low_memory=False,\n",
    "    usecols=usecols,\n",
    ")\n",
    "\n",
    "rename_map = {\n",
    "    'Arg1_RawText': 'Arg1',\n",
    "    'Arg2_RawText': 'Arg2',\n",
    "    'ConnHeadSemClass1': 'Conn1Sem1',\n",
    "    'ConnHeadSemClass2': 'Conn1Sem2',\n",
    "    'Conn2SemClass1': 'Conn2Sem1',\n",
    "    'Conn2SemClass2': 'Conn2Sem2',\n",
    "}\n",
    "df.rename(columns=rename_map, inplace=True)\n",
    "init_df = df.copy()\n",
    "\n",
    "df = df[df['Relation']=='Implicit']\n",
    "# print(df.shape)\n",
    "\n",
    "train_df = df[~df['Section'].isin([0, 1, 21, 22, 23, 24])]\n",
    "dev_df = df[df['Section'].isin([0, 1])]\n",
    "test_df = df[df['Section'].isin([21, 22])]\n",
    "\n",
    "from collections import Counter\n",
    "cnt = Counter(df['Conn1Sem1'])\n",
    "sorted(cnt.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Comparison',\n",
       " 'Comparison.Concession',\n",
       " 'Comparison.Concession.Contra-expectation',\n",
       " 'Comparison.Concession.Expectation',\n",
       " 'Comparison.Contrast',\n",
       " 'Comparison.Contrast.Juxtaposition',\n",
       " 'Comparison.Contrast.Opposition',\n",
       " 'Comparison.Pragmatic concession',\n",
       " 'Comparison.Pragmatic contrast',\n",
       " 'Contingency',\n",
       " 'Contingency.Cause',\n",
       " 'Contingency.Cause.Reason',\n",
       " 'Contingency.Cause.Result',\n",
       " 'Contingency.Condition.Hypothetical',\n",
       " 'Contingency.Pragmatic cause.Justification',\n",
       " 'Contingency.Pragmatic condition.Relevance',\n",
       " 'Expansion',\n",
       " 'Expansion.Alternative',\n",
       " 'Expansion.Alternative.Chosen alternative',\n",
       " 'Expansion.Alternative.Conjunctive',\n",
       " 'Expansion.Conjunction',\n",
       " 'Expansion.Exception',\n",
       " 'Expansion.Instantiation',\n",
       " 'Expansion.List',\n",
       " 'Expansion.Restatement',\n",
       " 'Expansion.Restatement.Equivalence',\n",
       " 'Expansion.Restatement.Generalization',\n",
       " 'Expansion.Restatement.Specification',\n",
       " 'Temporal',\n",
       " 'Temporal.Asynchronous.Precedence',\n",
       " 'Temporal.Asynchronous.Succession',\n",
       " 'Temporal.Synchrony']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = df['Conn1Sem1'].unique().tolist()\n",
    "sorted(labels)\n",
    "# labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## level1&2 statistic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expansion.Conjunction 2872\n",
      "Expansion.Restatement 2404\n",
      "Expansion.Instantiation 1063\n",
      "Expansion.List 338\n",
      "Expansion.Alternative 147\n",
      "Contingency.Cause 3270\n",
      "Contingency.Pragmatic cause 64\n",
      "Comparison.Contrast 1607\n",
      "Comparison.Concession 183\n",
      "Temporal.Asynchronous 532\n",
      "Temporal.Synchrony 203\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "12683"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# GOLF\n",
    "selected_second_senses = [\n",
    "    'Expansion.Conjunction',\n",
    "    'Expansion.Restatement',\n",
    "    'Expansion.Instantiation', \n",
    "    'Expansion.List',\n",
    "    'Expansion.Alternative', \n",
    "    'Contingency.Cause',\n",
    "    'Contingency.Pragmatic cause', \n",
    "    'Comparison.Contrast',\n",
    "    'Comparison.Concession',\n",
    "    'Temporal.Asynchronous', \n",
    "    'Temporal.Synchrony', \n",
    "]\n",
    "cnt_df = train_df\n",
    "# cnt_df = dev_df\n",
    "cnt = 0\n",
    "rec = {}\n",
    "for sense in cnt_df['Conn1Sem1']:\n",
    "    sense_l2 = '.'.join(sense.split('.')[:2])\n",
    "    if sense_l2 in selected_second_senses:\n",
    "        cnt += 1\n",
    "        rec[sense_l2] = rec.get(sense_l2,0)+1\n",
    "for sense in cnt_df['Conn1Sem2']:\n",
    "    if pd.isna(sense):\n",
    "        continue\n",
    "    sense_l2 = '.'.join(sense.split('.')[:2])\n",
    "    if sense_l2 in selected_second_senses:\n",
    "        cnt += 1\n",
    "        rec[sense_l2] = rec.get(sense_l2,0)+1\n",
    "for k in selected_second_senses:\n",
    "    print(k,rec[k])\n",
    "sum(rec.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12406"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# PCP\n",
    "train_df.shape\n",
    "dev_df.shape\n",
    "test_df.shape\n",
    "selected_second_senses = set([\n",
    "    'Temporal.Asynchronous', 'Temporal.Synchrony', 'Contingency.Cause',\n",
    "    'Contingency.Pragmatic cause', 'Comparison.Contrast', 'Comparison.Concession',\n",
    "    'Expansion.Conjunction', 'Expansion.Instantiation', 'Expansion.Restatement',\n",
    "    'Expansion.Alternative', 'Expansion.List'\n",
    "])\n",
    "cnt_df = train_df\n",
    "# cnt_df = dev_df\n",
    "# cnt_df = test_df\n",
    "cnt = 0\n",
    "for sense in cnt_df['Conn1Sem1']:\n",
    "    sense_l2 = '.'.join(sense.split('.')[:2])\n",
    "    if sense_l2 in selected_second_senses:\n",
    "        cnt += 1\n",
    "cnt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 一级多标签统计"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sort_dict(dct):\n",
    "    return dict(sorted(dct.items(), key=lambda x:-x[1]))\n",
    "    \n",
    "class analyse_level1_label:\n",
    "    labels = 'Temporal Comparison Contingency Expansion'.split()\n",
    "    \n",
    "    @classmethod\n",
    "    def str_to_label(cls, string):\n",
    "        return string.split('.')[0]\n",
    "    \n",
    "    @classmethod\n",
    "    def get_item_labels(cls, item):\n",
    "        primary_label = cls.str_to_label(item.Conn1Sem1)\n",
    "        secondary_labels = []\n",
    "        for s in [item.Conn1Sem2, item.Conn2Sem1, item.Conn2Sem2]:\n",
    "            if not pd.isna(s):\n",
    "                secondary_labels.append(cls.str_to_label(s))\n",
    "        return primary_label, secondary_labels\n",
    "        \n",
    "    def __new__(cls, df, sort_res=True):\n",
    "        rec = {l:{ll:0 for ll in ['']+cls.labels}for l in cls.labels}\n",
    "        for p in range(df.shape[0]):\n",
    "            item = df.iloc[p]\n",
    "            primary_label, secondary_labels = cls.get_item_labels(item)\n",
    "            if not secondary_labels:\n",
    "                rec[primary_label][''] += 1\n",
    "            else:\n",
    "                for l in secondary_labels:\n",
    "                    rec[primary_label][l] += 1\n",
    "\n",
    "        if sort_res:\n",
    "            for k in rec:\n",
    "                rec[k] = sort_dict(rec[k])\n",
    "                \n",
    "        import json\n",
    "        rec_string = json.dumps(rec, ensure_ascii=False, indent=2)\n",
    "        print('num of level1 labels')\n",
    "        print(rec_string)\n",
    "        \n",
    "        rank = {}\n",
    "        for k in rec:\n",
    "            vals = sorted(cls.labels, key=lambda x:rec[k][x])\n",
    "            rank[k] = [v for v in vals if k != v]\n",
    "        rank_string = json.dumps(rank, ensure_ascii=False, indent=2)\n",
    "        print('\\nrank of level1 labels')\n",
    "        print(rank_string)\n",
    "        pass\n",
    "    \n",
    "\n",
    "analyse_level1_label(train_df)    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PDTB 3.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## preprocess: merge section to csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['section',\n",
       " 'filename',\n",
       " 'relation_type',\n",
       " 'arg1',\n",
       " 'arg2',\n",
       " 'conn1',\n",
       " 'conn1_sense1',\n",
       " 'conn1_sense2',\n",
       " 'conn2',\n",
       " 'conn2_sense1',\n",
       " 'conn2_sense2']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# prepare `sections` by `preprocess_pdtb3.py`\n",
    "fold_path = r'D:\\0--data\\projects\\04.01-IDRR\\IDRR-base\\CorpusData\\PDTB3\\data\\sections'\n",
    "\n",
    "columns = []\n",
    "data_list = []\n",
    "for p in range(25):\n",
    "    with open(os.path.join(fold_path, str(p).rjust(2,'0')+'.tsv'), 'r', encoding='utf8')as file:\n",
    "        content = list(file.readlines())\n",
    "        columns = content[0]\n",
    "        data_list.extend(content[1:])\n",
    "columns = columns.strip().split('\\t')\n",
    "data_list = [line.strip('\\n').split('\\t')for line in data_list if line.strip()]\n",
    "# print(set(map(len, data_list)))\n",
    "df = pd.DataFrame(data_list, columns=columns)\n",
    "columns\n",
    "# df.shape\n",
    "# df.to_csv(r'D:\\0--data\\projects\\04.01-IDRR\\IDRR-base\\CorpusData\\PDTB3\\pdtb3_implicit.csv', sep='\\t', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "for line in df['arg2']:\n",
    "    # if len(re.findall(r'\\d', line)) > 3:\n",
    "    #     print(line)\n",
    "    if 'wj_' in line:\n",
    "        print(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Comparison.Concession+SpeechAct.Arg2-as-denier+SpeechAct',\n",
       " 'Comparison.Concession.Arg1-as-denier',\n",
       " 'Comparison.Concession.Arg2-as-denier',\n",
       " 'Comparison.Contrast',\n",
       " 'Comparison.Similarity',\n",
       " 'Contingency.Cause+Belief.Reason+Belief',\n",
       " 'Contingency.Cause+Belief.Result+Belief',\n",
       " 'Contingency.Cause+SpeechAct.Reason+SpeechAct',\n",
       " 'Contingency.Cause+SpeechAct.Result+SpeechAct',\n",
       " 'Contingency.Cause.Reason',\n",
       " 'Contingency.Cause.Result',\n",
       " 'Contingency.Condition+SpeechAct',\n",
       " 'Contingency.Condition.Arg1-as-cond',\n",
       " 'Contingency.Condition.Arg2-as-cond',\n",
       " 'Contingency.Purpose.Arg1-as-goal',\n",
       " 'Contingency.Purpose.Arg2-as-goal',\n",
       " 'Expansion.Conjunction',\n",
       " 'Expansion.Disjunction',\n",
       " 'Expansion.Equivalence',\n",
       " 'Expansion.Exception.Arg1-as-excpt',\n",
       " 'Expansion.Exception.Arg2-as-excpt',\n",
       " 'Expansion.Instantiation.Arg1-as-instance',\n",
       " 'Expansion.Instantiation.Arg2-as-instance',\n",
       " 'Expansion.Level-of-detail.Arg1-as-detail',\n",
       " 'Expansion.Level-of-detail.Arg2-as-detail',\n",
       " 'Expansion.Manner.Arg1-as-manner',\n",
       " 'Expansion.Manner.Arg2-as-manner',\n",
       " 'Expansion.Substitution.Arg2-as-subst',\n",
       " 'Temporal.Asynchronous.Precedence',\n",
       " 'Temporal.Asynchronous.Succession',\n",
       " 'Temporal.Synchronous']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(set(df['conn1_sense1']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## other's preprocess (strange)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# train.csv 9308\n",
    "# sections\\12.tsv 387\n",
    "\n",
    "train_file = r'D:\\0--data\\projects\\04.01-IDRR\\IDRR-base\\CorpusData\\PDTB3\\processed\\train.tsv'\n",
    "train_file = r'D:\\0--data\\projects\\04.01-IDRR\\IDRR-base\\tmp\\ttmp\\train.tsv'\n",
    "# df\n",
    "with open(train_file, 'r', encoding='utf8')as f:\n",
    "    content = list(f.readlines())\n",
    "    for p in range(9308, 9310):\n",
    "        # print(repr(content[p]))\n",
    "        # print(p, len(content[p].split('\\t')))\n",
    "        # for d in content[p].split('\\t'):\n",
    "        #     print(d)\n",
    "        pass\n",
    "fake_content = [content[0],content[1],content[9307],content[9308],content[9309]]\n",
    "# with open(r'D:\\0--data\\projects\\04.01-IDRR\\IDRR-base\\tmp\\fake.csv', 'w', encoding='utf8')as f:\n",
    "#     f.writelines(fake_content)\n",
    "# with open(r'D:\\0--data\\projects\\04.01-IDRR\\IDRR-base\\tmp\\fake.tsv', 'w', encoding='utf8')as f:\n",
    "#     f.writelines(fake_content)\n",
    "\n",
    "content = [line.strip().split('\\t')for line in content]\n",
    "# for p, line in enumerate(content):\n",
    "#     if len(line) != 10:\n",
    "#         print(p)\n",
    "# print(content[9308:9310])\n",
    "skiprows = [\n",
    "    9308,\n",
    "]\n",
    "df = pd.read_csv(train_file, sep='\\t'\n",
    "                 , skiprows=skiprows, encoding='latin1'\n",
    "                 )\n",
    "# df.columns\n",
    "df.iloc[0]\n",
    "# sorted(set(df['full_sense']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "strange_file = r'D:\\0--data\\projects\\04.01-IDRR\\IDRR-base\\CorpusData\\PDTB3\\data\\sections\\12.tsv'\n",
    "cur_pd12 = pd.read_csv(strange_file, delimiter='\\t', skiprows=[386])\n",
    "\n",
    "with open(strange_file, 'r', encoding='utf8')as file:\n",
    "    content = list(file.readlines())\n",
    "print(content[385])\n",
    "print(content[386])\n",
    "print(content[387])\n",
    "print(cur_pd12.iloc[385:388])\n",
    "print(len(content), cur_pd12.shape)\n",
    "# print(cur_pd12.iloc[386])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Comparison.Concession+SpeechAct.Arg2-as-denier+SpeechAct',\n",
       " 'Comparison.Concession.Arg1-as-denier',\n",
       " 'Comparison.Concession.Arg2-as-denier',\n",
       " 'Comparison.Contrast',\n",
       " 'Comparison.Similarity',\n",
       " 'Contingency.Cause+Belief.Reason+Belief',\n",
       " 'Contingency.Cause+Belief.Result+Belief',\n",
       " 'Contingency.Cause+SpeechAct.Reason+SpeechAct',\n",
       " 'Contingency.Cause+SpeechAct.Result+SpeechAct',\n",
       " 'Contingency.Cause.Reason',\n",
       " 'Contingency.Cause.Result',\n",
       " 'Contingency.Condition+SpeechAct',\n",
       " 'Contingency.Condition.Arg1-as-cond',\n",
       " 'Contingency.Condition.Arg2-as-cond',\n",
       " 'Contingency.Purpose.Arg1-as-goal',\n",
       " 'Contingency.Purpose.Arg2-as-goal',\n",
       " 'Expansion.Conjunction',\n",
       " 'Expansion.Disjunction',\n",
       " 'Expansion.Equivalence',\n",
       " 'Expansion.Exception.Arg1-as-excpt',\n",
       " 'Expansion.Exception.Arg2-as-excpt',\n",
       " 'Expansion.Instantiation.Arg1-as-instance',\n",
       " 'Expansion.Instantiation.Arg2-as-instance',\n",
       " 'Expansion.Level-of-detail.Arg1-as-detail',\n",
       " 'Expansion.Level-of-detail.Arg2-as-detail',\n",
       " 'Expansion.Manner.Arg1-as-manner',\n",
       " 'Expansion.Manner.Arg2-as-manner',\n",
       " 'Expansion.Substitution.Arg2-as-subst',\n",
       " 'Temporal.Asynchronous.Precedence',\n",
       " 'Temporal.Asynchronous.Succession',\n",
       " 'Temporal.Synchronous']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(r'D:\\0--data\\projects\\04.01-IDRR\\IDRR-base\\CorpusData\\PDTB3\\pdtb3_implicit.csv', delimiter='\\t')\n",
    "\n",
    "train_df = df[df['section'].isin(list(range(2,21)))]\n",
    "dev_df = df[df['section'].isin([0,1])]\n",
    "test_df = df[df['section'].isin([21,22])]\n",
    "\n",
    "df.columns\n",
    "df.shape\n",
    "from collections import Counter\n",
    "cnt = Counter(df['conn1_sense1'])\n",
    "sorted(cnt.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## level1&2 statistic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32md:\\0--data\\projects\\04.01-IDRR数据\\IDRR-base\\CorpusData\\analyse.ipynb Cell 20\u001b[0m line \u001b[0;36m1\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/0--data/projects/04.01-IDRR%E6%95%B0%E6%8D%AE/IDRR-base/CorpusData/analyse.ipynb#X25sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m train_df\u001b[39m.\u001b[39mshape, dev_df\u001b[39m.\u001b[39mshape, test_df\u001b[39m.\u001b[39mshape\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/0--data/projects/04.01-IDRR%E6%95%B0%E6%8D%AE/IDRR-base/CorpusData/analyse.ipynb#X25sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39m# dev_df.shape\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/0--data/projects/04.01-IDRR%E6%95%B0%E6%8D%AE/IDRR-base/CorpusData/analyse.ipynb#X25sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39m# test_df.shape\u001b[39;00m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'train_df' is not defined"
     ]
    }
   ],
   "source": [
    "train_df.shape, dev_df.shape, test_df.shape\n",
    "# dev_df.shape\n",
    "# test_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Expansion.Conjunction',\n",
       " 'Expansion.Level-of-detail',\n",
       " 'Expansion.Instantiation',\n",
       " 'Expansion.Manner',\n",
       " 'Expansion.Substitution',\n",
       " 'Expansion.Equivalence',\n",
       " 'Contingency.Cause',\n",
       " 'Contingency.Purpose',\n",
       " 'Contingency.Cause+Belief',\n",
       " 'Contingency.Condition',\n",
       " 'Comparison.Concession',\n",
       " 'Comparison.Contrast',\n",
       " 'Temporal.Asynchronous',\n",
       " 'Temporal.Synchronous']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "import json\n",
    "selected_second_senses = '''\n",
    "    Expansion.Conjunction Expansion.Level-of-detail Expansion.Instantiation\n",
    "    Expansion.Manner Expansion.Substitution Expansion.Equivalence\n",
    "    Contingency.Cause Contingency.Purpose Contingency.Cause+Belief\n",
    "    Contingency.Condition\n",
    "    Comparison.Concession\n",
    "    Comparison.Contrast\n",
    "    Temporal.Asynchronous\n",
    "    Temporal.Synchronous\n",
    "'''.split()\n",
    "cur_df = train_df\n",
    "cur_df = dev_df\n",
    "cur_df = test_df\n",
    "rec = defaultdict(int)\n",
    "cnt = 0\n",
    "for sense in cur_df['conn1_sense1']:\n",
    "    sense_l2 = '.'.join(sense.split('.')[:2])\n",
    "    # sense_l2 = sense\n",
    "    if sense_l2 in selected_second_senses:\n",
    "        rec[sense_l2] += 1\n",
    "        cnt += 1\n",
    "# cnt\n",
    "# rec\n",
    "selected_second_senses\n",
    "# for sense in cur_df['conn2_sense1']:\n",
    "#     if pd.isna(sense):\n",
    "#         continue\n",
    "#     sense_l2 = '.'.join(sense.split('.')[:2])\n",
    "#     # sense_l2 = sense\n",
    "#     if sense_l2 in selected_second_senses:\n",
    "#         rec[sense_l2] += 1\n",
    "# cnt\n",
    "# for k in selected_second_senses:\n",
    "#     print(k, rec[k])\n",
    "# sum(rec.values())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CoNLL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Arg1': {'CharacterSpanList': [[9, 240]],\n",
       "  'RawText': 'In an Oct. 19 review of \"The Misanthrope\" at Chicago\\'s Goodman Theatre (\"Revitalized Classics Take the Stage in Windy City,\" Leisure & Arts), the role of Celimene, played by Kim Cattrall, was mistakenly attributed to Christina Haag',\n",
       "  'TokenList': [[9, 11, 0, 0, 0],\n",
       "   [12, 14, 1, 0, 1],\n",
       "   [15, 19, 2, 0, 2],\n",
       "   [20, 22, 3, 0, 3],\n",
       "   [23, 29, 4, 0, 4],\n",
       "   [30, 32, 5, 0, 5],\n",
       "   [33, 34, 6, 0, 6],\n",
       "   [34, 37, 7, 0, 7],\n",
       "   [38, 49, 8, 0, 8],\n",
       "   [49, 50, 9, 0, 9],\n",
       "   [51, 53, 10, 0, 10],\n",
       "   [54, 61, 11, 0, 11],\n",
       "   [61, 63, 12, 0, 12],\n",
       "   [64, 71, 13, 0, 13],\n",
       "   [72, 79, 14, 0, 14],\n",
       "   [80, 81, 15, 0, 15],\n",
       "   [81, 82, 16, 0, 16],\n",
       "   [82, 93, 17, 0, 17],\n",
       "   [94, 102, 18, 0, 18],\n",
       "   [103, 107, 19, 0, 19],\n",
       "   [108, 111, 20, 0, 20],\n",
       "   [112, 117, 21, 0, 21],\n",
       "   [118, 120, 22, 0, 22],\n",
       "   [121, 126, 23, 0, 23],\n",
       "   [127, 131, 24, 0, 24],\n",
       "   [131, 132, 25, 0, 25],\n",
       "   [132, 133, 26, 0, 26],\n",
       "   [134, 141, 27, 0, 27],\n",
       "   [142, 143, 28, 0, 28],\n",
       "   [144, 148, 29, 0, 29],\n",
       "   [148, 149, 30, 0, 30],\n",
       "   [149, 150, 31, 0, 31],\n",
       "   [151, 154, 32, 0, 32],\n",
       "   [155, 159, 33, 0, 33],\n",
       "   [160, 162, 34, 0, 34],\n",
       "   [163, 171, 35, 0, 35],\n",
       "   [171, 172, 36, 0, 36],\n",
       "   [173, 179, 37, 0, 37],\n",
       "   [180, 182, 38, 0, 38],\n",
       "   [183, 186, 39, 0, 39],\n",
       "   [187, 195, 40, 0, 40],\n",
       "   [195, 196, 41, 0, 41],\n",
       "   [197, 200, 42, 0, 42],\n",
       "   [201, 211, 43, 0, 43],\n",
       "   [212, 222, 44, 0, 44],\n",
       "   [223, 225, 45, 0, 45],\n",
       "   [226, 235, 46, 0, 46],\n",
       "   [236, 240, 47, 0, 47]]},\n",
       " 'Arg2': {'CharacterSpanList': [[242, 264]],\n",
       "  'RawText': 'Ms. Haag plays Elianti',\n",
       "  'TokenList': [[242, 245, 49, 1, 0],\n",
       "   [246, 250, 50, 1, 1],\n",
       "   [251, 256, 51, 1, 2],\n",
       "   [257, 264, 52, 1, 3]]},\n",
       " 'Connective': {'CharacterSpanList': [],\n",
       "  'RawText': 'however',\n",
       "  'TokenList': []},\n",
       " 'DocID': 'wsj_0200',\n",
       " 'ID': 3173,\n",
       " 'Sense': ['Comparison.Contrast'],\n",
       " 'Type': 'Implicit'}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "train_file = r'D:\\0--data\\projects\\04.01-IDRR\\IDRR-base\\CorpusData\\2015-2016_conll_shared_task\\data\\conll16st-en-03-29-16-train\\relations.json'\n",
    "dev_file = r'D:\\0--data\\projects\\04.01-IDRR\\IDRR-base\\CorpusData\\2015-2016_conll_shared_task\\data\\conll16st-en-03-29-16-dev\\relations.json'\n",
    "test_file = r'D:\\0--data\\projects\\04.01-IDRR\\IDRR-base\\CorpusData\\2015-2016_conll_shared_task\\data\\conll16st-en-03-29-16-test\\relations.json'\n",
    "blind_test_file = r'D:\\0--data\\projects\\04.01-IDRR\\IDRR-base\\CorpusData\\2015-2016_conll_shared_task\\data\\conll16st-en-03-29-16-blind-test\\relations.json'\n",
    "\n",
    "def get_dicts(file):\n",
    "    # dicts = []\n",
    "    with open(file, 'r', encoding='utf8')as f:\n",
    "        dicts = [json.loads(line)for line in f.readlines()]\n",
    "    return dicts\n",
    "\n",
    "train_dicts = get_dicts(train_file)\n",
    "train_dicts = [p for p in train_dicts if p['Type'] == 'Implicit']\n",
    "sample = train_dicts[0]\n",
    "sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Comparison',\n",
       " 'Comparison.Concession',\n",
       " 'Comparison.Contrast',\n",
       " 'Contingency',\n",
       " 'Contingency.Cause',\n",
       " 'Contingency.Cause.Reason',\n",
       " 'Contingency.Cause.Result',\n",
       " 'Contingency.Condition',\n",
       " 'EntRel',\n",
       " 'Expansion',\n",
       " 'Expansion.Alternative',\n",
       " 'Expansion.Alternative.Chosen alternative',\n",
       " 'Expansion.Conjunction',\n",
       " 'Expansion.Exception',\n",
       " 'Expansion.Instantiation',\n",
       " 'Expansion.Restatement',\n",
       " 'Temporal',\n",
       " 'Temporal.Asynchronous',\n",
       " 'Temporal.Asynchronous.Precedence',\n",
       " 'Temporal.Asynchronous.Succession',\n",
       " 'Temporal.Synchrony']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "total_senses = [q for p in get_dicts(train_file) for q in p['Sense']]\n",
    "sorted(set(total_senses))\n",
    "\n",
    "total_senses_l2 = ['.'.join(p.split('.')[:])for p in total_senses ]\n",
    "sorted(set(total_senses_l2))\n",
    "# Counter(total_senses_l2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Label Map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data_path_pdtb2 = r'D:\\0--data\\projects\\04.01-IDRR\\IDRR-base\\CorpusData\\PDTB2\\pdtb2.csv'\n",
    "data_path_pdtb3 = r'D:\\0--data\\projects\\04.01-IDRR\\IDRR-base\\CorpusData\\PDTB3\\pdtb3_implicit.csv'\n",
    "data_path_conll = r'D:\\0--data\\projects\\04.01-IDRR\\IDRR-base\\CorpusData\\CoNLL16'\n",
    "\n",
    "sense_pdtb2 = ['Comparison',\n",
    " 'Comparison.Concession',\n",
    " 'Comparison.Concession.Contra-expectation',\n",
    " 'Comparison.Concession.Expectation',\n",
    " 'Comparison.Contrast',\n",
    " 'Comparison.Contrast.Juxtaposition',\n",
    " 'Comparison.Contrast.Opposition',\n",
    " 'Comparison.Pragmatic concession',\n",
    " 'Comparison.Pragmatic contrast',\n",
    " 'Contingency',\n",
    " 'Contingency.Cause',\n",
    " 'Contingency.Cause.Reason',\n",
    " 'Contingency.Cause.Result',\n",
    " 'Contingency.Condition.Hypothetical',\n",
    " 'Contingency.Pragmatic cause.Justification',\n",
    " 'Contingency.Pragmatic condition.Relevance',\n",
    " 'Expansion',\n",
    " 'Expansion.Alternative',\n",
    " 'Expansion.Alternative.Chosen alternative',\n",
    " 'Expansion.Alternative.Conjunctive',\n",
    " 'Expansion.Conjunction',\n",
    " 'Expansion.Exception',\n",
    " 'Expansion.Instantiation',\n",
    " 'Expansion.List',\n",
    " 'Expansion.Restatement',\n",
    " 'Expansion.Restatement.Equivalence',\n",
    " 'Expansion.Restatement.Generalization',\n",
    " 'Expansion.Restatement.Specification',\n",
    " 'Temporal',\n",
    " 'Temporal.Asynchronous.Precedence',\n",
    " 'Temporal.Asynchronous.Succession',\n",
    " 'Temporal.Synchrony']\n",
    "sense_pdtb3 = ['Comparison.Concession+SpeechAct.Arg2-as-denier+SpeechAct',\n",
    " 'Comparison.Concession.Arg1-as-denier',\n",
    " 'Comparison.Concession.Arg2-as-denier',\n",
    " 'Comparison.Contrast',\n",
    " 'Comparison.Similarity',\n",
    " 'Contingency.Cause+Belief.Reason+Belief',\n",
    " 'Contingency.Cause+Belief.Result+Belief',\n",
    " 'Contingency.Cause+SpeechAct.Reason+SpeechAct',\n",
    " 'Contingency.Cause+SpeechAct.Result+SpeechAct',\n",
    " 'Contingency.Cause.Reason',\n",
    " 'Contingency.Cause.Result',\n",
    " 'Contingency.Condition+SpeechAct',\n",
    " 'Contingency.Condition.Arg1-as-cond',\n",
    " 'Contingency.Condition.Arg2-as-cond',\n",
    " 'Contingency.Purpose.Arg1-as-goal',\n",
    " 'Contingency.Purpose.Arg2-as-goal',\n",
    " 'Expansion.Conjunction',\n",
    " 'Expansion.Disjunction',\n",
    " 'Expansion.Equivalence',\n",
    " 'Expansion.Exception.Arg1-as-excpt',\n",
    " 'Expansion.Exception.Arg2-as-excpt',\n",
    " 'Expansion.Instantiation.Arg1-as-instance',\n",
    " 'Expansion.Instantiation.Arg2-as-instance',\n",
    " 'Expansion.Level-of-detail.Arg1-as-detail',\n",
    " 'Expansion.Level-of-detail.Arg2-as-detail',\n",
    " 'Expansion.Manner.Arg1-as-manner',\n",
    " 'Expansion.Manner.Arg2-as-manner',\n",
    " 'Expansion.Substitution.Arg2-as-subst',\n",
    " 'Temporal.Asynchronous.Precedence',\n",
    " 'Temporal.Asynchronous.Succession',\n",
    " 'Temporal.Synchronous']\n",
    "sense_conll = ['Comparison',\n",
    " 'Comparison.Concession',\n",
    " 'Comparison.Contrast',\n",
    " 'Contingency',\n",
    " 'Contingency.Cause',\n",
    " 'Contingency.Cause.Reason',\n",
    " 'Contingency.Cause.Result',\n",
    " 'Contingency.Condition',\n",
    " 'Expansion',\n",
    " 'Expansion.Alternative',\n",
    " 'Expansion.Alternative.Chosen alternative',\n",
    " 'Expansion.Conjunction',\n",
    " 'Expansion.Exception',\n",
    " 'Expansion.Instantiation',\n",
    " 'Expansion.Restatement',\n",
    " 'Temporal',\n",
    " 'Temporal.Asynchronous.Precedence',\n",
    " 'Temporal.Asynchronous.Succession',\n",
    " 'Temporal.Synchrony']\n",
    "\n",
    "sense_dic = {\n",
    "    'pdtb2': sense_pdtb2,\n",
    "    'pdtb3': sense_pdtb3,\n",
    "    'conll': sense_conll,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Comparison',\n",
       " 'Comparison.Concession',\n",
       " 'Comparison.Contrast',\n",
       " 'Contingency',\n",
       " 'Contingency.Cause',\n",
       " 'Contingency.Cause.Reason',\n",
       " 'Contingency.Cause.Result',\n",
       " 'Contingency.Condition',\n",
       " 'Expansion',\n",
       " 'Expansion.Alternative',\n",
       " 'Expansion.Alternative.Chosen alternative',\n",
       " 'Expansion.Conjunction',\n",
       " 'Expansion.Exception',\n",
       " 'Expansion.Instantiation',\n",
       " 'Expansion.Restatement',\n",
       " 'Temporal',\n",
       " 'Temporal.Asynchronous.Precedence',\n",
       " 'Temporal.Asynchronous.Succession',\n",
       " 'Temporal.Synchrony']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sense_pdtb2\n",
    "sense_pdtb3\n",
    "sense_conll"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## level 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "order = 'Temporal Comparison Contingency Expansion'.split()\n",
    "order.sort()\n",
    "\n",
    "def sense_to_id(sense):\n",
    "    return order.index(sense.split('.')[0])\n",
    "\n",
    "label_map = {}\n",
    "for data_name, sense_list in sense_dic.items():\n",
    "    label_map[data_name] = {\n",
    "        sense:sense_to_id(sense)\n",
    "        for sense in sense_list\n",
    "    }\n",
    "json_path = r'D:\\0--data\\projects\\04.01-IDRR\\IDRR-base\\label_map\\level1.json'\n",
    "with open(json_path, 'w', encoding='utf8')as f:\n",
    "    json.dump(label_map, f, indent=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## level2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "\n",
    "label_map = {}\n",
    "for data_name, sense_list in sense_dic.items():\n",
    "    label_map[data_name] = {\n",
    "        sense:p\n",
    "        for p,sense in enumerate(sense_list)\n",
    "    }\n",
    "json_path = r'D:\\0--data\\projects\\04.01-IDRR\\IDRR-base\\label_map\\level2.json'\n",
    "with open(json_path, 'w', encoding='utf8')as f:\n",
    "    json.dump(label_map, f, indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sd = {'Concession':'Comparison','Contrast':'Comparison','Cause':'Contingency','Cause+Belief':'Contingency',\n",
    "                    'Condition':'Contingency','Purpose':'Contingency',\n",
    "                    'Conjunction':'Expansion','Equivalence':'Expansion','Instantiation':'Expansion','Level-of-detail':'Expansion',\n",
    "                    'Manner':'Expansion','Substitution':'Expansion',\n",
    "                    'Asynchronous':'Temporal','Synchronous':'Temporal',\n",
    "                    'None':'None'}\n",
    "len(sd)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python_main",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
