{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PDTB 2.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "usecols = [\n",
    "    'Relation', 'Section', \n",
    "    'Arg1_RawText', 'Arg2_RawText', \n",
    "    'Conn1', 'Conn2',\n",
    "    'ConnHeadSemClass1', 'ConnHeadSemClass2',\n",
    "    'Conn2SemClass1', 'Conn2SemClass2'\n",
    "]\n",
    "df = pd.read_csv(\n",
    "    r'D:\\0--data\\projects\\04.01-IDRR数据\\IDRR-base\\CorpusData\\PDTB2\\pdtb2.csv',\n",
    "    low_memory=False,\n",
    "    usecols=usecols,\n",
    ")\n",
    "\n",
    "rename_map = {\n",
    "    'Arg1_RawText': 'Arg1',\n",
    "    'Arg2_RawText': 'Arg2',\n",
    "    'ConnHeadSemClass1': 'Conn1Sem1',\n",
    "    'ConnHeadSemClass2': 'Conn1Sem2',\n",
    "    'Conn2SemClass1': 'Conn2Sem1',\n",
    "    'Conn2SemClass2': 'Conn2Sem2',\n",
    "}\n",
    "df.rename(columns=rename_map, inplace=True)\n",
    "init_df = df.copy()\n",
    "\n",
    "df = df[df['Relation']=='Implicit']\n",
    "# print(df.shape)\n",
    "\n",
    "train_df = df[~df['Section'].isin([0, 1, 21, 22, 23, 24])]\n",
    "dev_df = df[df['Section'].isin([0, 1])]\n",
    "test_df = df[df['Section'].isin([21, 22])]\n",
    "\n",
    "from collections import Counter\n",
    "cnt = Counter(df['Conn1Sem1'])\n",
    "sorted(cnt.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = df['Conn1Sem1'].unique().tolist()\n",
    "sorted(labels)\n",
    "# labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## level1&2 statistic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GOLF\n",
    "selected_second_senses = [\n",
    "    'Expansion.Conjunction',\n",
    "    'Expansion.Restatement',\n",
    "    'Expansion.Instantiation', \n",
    "    'Expansion.List',\n",
    "    'Expansion.Alternative', \n",
    "    'Contingency.Cause',\n",
    "    'Contingency.Pragmatic cause', \n",
    "    'Comparison.Contrast',\n",
    "    'Comparison.Concession',\n",
    "    'Temporal.Asynchronous', \n",
    "    'Temporal.Synchrony', \n",
    "]\n",
    "cnt_df = train_df\n",
    "# cnt_df = dev_df\n",
    "cnt = 0\n",
    "rec = {}\n",
    "for sense in cnt_df['Conn1Sem1']:\n",
    "    sense_l2 = '.'.join(sense.split('.')[:2])\n",
    "    if sense_l2 in selected_second_senses:\n",
    "        cnt += 1\n",
    "        rec[sense_l2] = rec.get(sense_l2,0)+1\n",
    "for sense in cnt_df['Conn1Sem2']:\n",
    "    if pd.isna(sense):\n",
    "        continue\n",
    "    sense_l2 = '.'.join(sense.split('.')[:2])\n",
    "    if sense_l2 in selected_second_senses:\n",
    "        cnt += 1\n",
    "        rec[sense_l2] = rec.get(sense_l2,0)+1\n",
    "for k in selected_second_senses:\n",
    "    print(k,rec[k])\n",
    "sum(rec.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PCP\n",
    "train_df.shape\n",
    "dev_df.shape\n",
    "test_df.shape\n",
    "selected_second_senses = set([\n",
    "    'Temporal.Asynchronous', 'Temporal.Synchrony', 'Contingency.Cause',\n",
    "    'Contingency.Pragmatic cause', 'Comparison.Contrast', 'Comparison.Concession',\n",
    "    'Expansion.Conjunction', 'Expansion.Instantiation', 'Expansion.Restatement',\n",
    "    'Expansion.Alternative', 'Expansion.List'\n",
    "])\n",
    "cnt_df = train_df\n",
    "# cnt_df = dev_df\n",
    "# cnt_df = test_df\n",
    "cnt = 0\n",
    "for sense in cnt_df['Conn1Sem1']:\n",
    "    sense_l2 = '.'.join(sense.split('.')[:2])\n",
    "    if sense_l2 in selected_second_senses:\n",
    "        cnt += 1\n",
    "cnt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 一级多标签统计"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sort_dict(dct):\n",
    "    return dict(sorted(dct.items(), key=lambda x:-x[1]))\n",
    "    \n",
    "class analyse_level1_label:\n",
    "    labels = 'Temporal Comparison Contingency Expansion'.split()\n",
    "    \n",
    "    @classmethod\n",
    "    def str_to_label(cls, string):\n",
    "        return string.split('.')[0]\n",
    "    \n",
    "    @classmethod\n",
    "    def get_item_labels(cls, item):\n",
    "        primary_label = cls.str_to_label(item.Conn1Sem1)\n",
    "        secondary_labels = []\n",
    "        for s in [item.Conn1Sem2, item.Conn2Sem1, item.Conn2Sem2]:\n",
    "            if not pd.isna(s):\n",
    "                secondary_labels.append(cls.str_to_label(s))\n",
    "        return primary_label, secondary_labels\n",
    "        \n",
    "    def __new__(cls, df, sort_res=True):\n",
    "        rec = {l:{ll:0 for ll in ['']+cls.labels}for l in cls.labels}\n",
    "        for p in range(df.shape[0]):\n",
    "            item = df.iloc[p]\n",
    "            primary_label, secondary_labels = cls.get_item_labels(item)\n",
    "            if not secondary_labels:\n",
    "                rec[primary_label][''] += 1\n",
    "            else:\n",
    "                for l in secondary_labels:\n",
    "                    rec[primary_label][l] += 1\n",
    "\n",
    "        if sort_res:\n",
    "            for k in rec:\n",
    "                rec[k] = sort_dict(rec[k])\n",
    "                \n",
    "        import json\n",
    "        rec_string = json.dumps(rec, ensure_ascii=False, indent=2)\n",
    "        print('num of level1 labels')\n",
    "        print(rec_string)\n",
    "        \n",
    "        rank = {}\n",
    "        for k in rec:\n",
    "            vals = sorted(cls.labels, key=lambda x:rec[k][x])\n",
    "            rank[k] = [v for v in vals if k != v]\n",
    "        rank_string = json.dumps(rank, ensure_ascii=False, indent=2)\n",
    "        print('\\nrank of level1 labels')\n",
    "        print(rank_string)\n",
    "        pass\n",
    "    \n",
    "\n",
    "analyse_level1_label(train_df)    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PDTB 3.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## preprocess: merge section to csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# prepare `sections` by `preprocess_pdtb3.py`\n",
    "fold_path = r'D:\\0--data\\projects\\04.01-IDRR数据\\IDRR-base\\CorpusData\\PDTB3\\data\\sections'\n",
    "\n",
    "columns = []\n",
    "data_list = []\n",
    "for p in range(25):\n",
    "    with open(os.path.join(fold_path, str(p).rjust(2,'0')+'.tsv'), 'r', encoding='utf8')as file:\n",
    "        content = list(file.readlines())\n",
    "        columns = content[0]\n",
    "        data_list.extend(content[1:])\n",
    "columns = columns.strip().split('\\t')\n",
    "data_list = [line.strip('\\n').split('\\t')for line in data_list if line.strip()]\n",
    "# print(set(map(len, data_list)))\n",
    "df = pd.DataFrame(data_list, columns=columns)\n",
    "columns\n",
    "# df.shape\n",
    "# df.to_csv(r'D:\\0--data\\projects\\04.01-IDRR数据\\IDRR-base\\CorpusData\\PDTB3\\pdtb3_implicit.csv', sep='\\t', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "for line in df['arg2']:\n",
    "    # if len(re.findall(r'\\d', line)) > 3:\n",
    "    #     print(line)\n",
    "    if 'wj_' in line:\n",
    "        print(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted(set(df['conn1_sense1']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## other's preprocess (strange)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# train.csv 9308\n",
    "# sections\\12.tsv 387\n",
    "\n",
    "train_file = r'D:\\0--data\\projects\\04.01-IDRR数据\\IDRR-base\\CorpusData\\PDTB3\\processed\\train.tsv'\n",
    "train_file = r'D:\\0--data\\projects\\04.01-IDRR数据\\IDRR-base\\tmp\\ttmp\\train.tsv'\n",
    "# df\n",
    "with open(train_file, 'r', encoding='utf8')as f:\n",
    "    content = list(f.readlines())\n",
    "    for p in range(9308, 9310):\n",
    "        # print(repr(content[p]))\n",
    "        # print(p, len(content[p].split('\\t')))\n",
    "        # for d in content[p].split('\\t'):\n",
    "        #     print(d)\n",
    "        pass\n",
    "fake_content = [content[0],content[1],content[9307],content[9308],content[9309]]\n",
    "# with open(r'D:\\0--data\\projects\\04.01-IDRR数据\\IDRR-base\\tmp\\fake.csv', 'w', encoding='utf8')as f:\n",
    "#     f.writelines(fake_content)\n",
    "# with open(r'D:\\0--data\\projects\\04.01-IDRR数据\\IDRR-base\\tmp\\fake.tsv', 'w', encoding='utf8')as f:\n",
    "#     f.writelines(fake_content)\n",
    "\n",
    "content = [line.strip().split('\\t')for line in content]\n",
    "# for p, line in enumerate(content):\n",
    "#     if len(line) != 10:\n",
    "#         print(p)\n",
    "# print(content[9308:9310])\n",
    "skiprows = [\n",
    "    9308,\n",
    "]\n",
    "df = pd.read_csv(train_file, sep='\\t'\n",
    "                 , skiprows=skiprows, encoding='latin1'\n",
    "                 )\n",
    "# df.columns\n",
    "df.iloc[0]\n",
    "# sorted(set(df['full_sense']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "strange_file = r'D:\\0--data\\projects\\04.01-IDRR数据\\IDRR-base\\CorpusData\\PDTB3\\data\\sections\\12.tsv'\n",
    "cur_pd12 = pd.read_csv(strange_file, delimiter='\\t', skiprows=[386])\n",
    "\n",
    "with open(strange_file, 'r', encoding='utf8')as file:\n",
    "    content = list(file.readlines())\n",
    "print(content[385])\n",
    "print(content[386])\n",
    "print(content[387])\n",
    "print(cur_pd12.iloc[385:388])\n",
    "print(len(content), cur_pd12.shape)\n",
    "# print(cur_pd12.iloc[386])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(r'D:\\0--data\\projects\\04.01-IDRR数据\\IDRR-base\\CorpusData\\PDTB3\\pdtb3_implicit.csv', delimiter='\\t')\n",
    "\n",
    "train_df = df[df['section'].isin(list(range(2,21)))]\n",
    "dev_df = df[df['section'].isin([0,1])]\n",
    "test_df = df[df['section'].isin([21,22])]\n",
    "\n",
    "df.columns\n",
    "df.shape\n",
    "from collections import Counter\n",
    "cnt = Counter(df['conn1_sense1'])\n",
    "sorted(cnt.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## level1&2 statistic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.shape, dev_df.shape, test_df.shape\n",
    "# dev_df.shape\n",
    "# test_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "import json\n",
    "selected_second_senses = '''\n",
    "    Expansion.Conjunction Expansion.Level-of-detail Expansion.Instantiation\n",
    "    Expansion.Manner Expansion.Substitution Expansion.Equivalence\n",
    "    Contingency.Cause Contingency.Purpose Contingency.Cause+Belief\n",
    "    Contingency.Condition\n",
    "    Comparison.Concession\n",
    "    Comparison.Contrast\n",
    "    Temporal.Asynchronous\n",
    "    Temporal.Synchronous\n",
    "'''.split()\n",
    "cur_df = train_df\n",
    "cur_df = dev_df\n",
    "cur_df = test_df\n",
    "rec = defaultdict(int)\n",
    "cnt = 0\n",
    "for sense in cur_df['conn1_sense1']:\n",
    "    sense_l2 = '.'.join(sense.split('.')[:2])\n",
    "    # sense_l2 = sense\n",
    "    if sense_l2 in selected_second_senses:\n",
    "        rec[sense_l2] += 1\n",
    "        cnt += 1\n",
    "# cnt\n",
    "# rec\n",
    "selected_second_senses\n",
    "# for sense in cur_df['conn2_sense1']:\n",
    "#     if pd.isna(sense):\n",
    "#         continue\n",
    "#     sense_l2 = '.'.join(sense.split('.')[:2])\n",
    "#     # sense_l2 = sense\n",
    "#     if sense_l2 in selected_second_senses:\n",
    "#         rec[sense_l2] += 1\n",
    "# cnt\n",
    "# for k in selected_second_senses:\n",
    "#     print(k, rec[k])\n",
    "# sum(rec.values())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CoNLL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "train_file = r'D:\\0--data\\projects\\04.01-IDRR数据\\IDRR-base\\CorpusData\\2015-2016_conll_shared_task\\data\\conll16st-en-03-29-16-train\\relations.json'\n",
    "dev_file = r'D:\\0--data\\projects\\04.01-IDRR数据\\IDRR-base\\CorpusData\\2015-2016_conll_shared_task\\data\\conll16st-en-03-29-16-dev\\relations.json'\n",
    "test_file = r'D:\\0--data\\projects\\04.01-IDRR数据\\IDRR-base\\CorpusData\\2015-2016_conll_shared_task\\data\\conll16st-en-03-29-16-test\\relations.json'\n",
    "blind_test_file = r'D:\\0--data\\projects\\04.01-IDRR数据\\IDRR-base\\CorpusData\\2015-2016_conll_shared_task\\data\\conll16st-en-03-29-16-blind-test\\relations.json'\n",
    "\n",
    "def get_dicts(file):\n",
    "    # dicts = []\n",
    "    with open(file, 'r', encoding='utf8')as f:\n",
    "        dicts = [json.loads(line)for line in f.readlines()]\n",
    "    return dicts\n",
    "\n",
    "train_dicts = get_dicts(train_file)\n",
    "train_dicts = [p for p in train_dicts if p['Type'] == 'Implicit']\n",
    "sample = train_dicts[0]\n",
    "sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "total_senses = [q for p in get_dicts(train_file) for q in p['Sense']]\n",
    "sorted(set(total_senses))\n",
    "\n",
    "total_senses_l2 = ['.'.join(p.split('.')[:])for p in total_senses ]\n",
    "sorted(set(total_senses_l2))\n",
    "# Counter(total_senses_l2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Label Map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data_path_pdtb2 = r'D:\\0--data\\projects\\04.01-IDRR数据\\IDRR-base\\CorpusData\\PDTB2\\pdtb2.csv'\n",
    "data_path_pdtb3 = r'D:\\0--data\\projects\\04.01-IDRR数据\\IDRR-base\\CorpusData\\PDTB3\\pdtb3_implicit.csv'\n",
    "data_path_conll = r'D:\\0--data\\projects\\04.01-IDRR数据\\IDRR-base\\CorpusData\\CoNLL16'\n",
    "\n",
    "sense_pdtb2 = ['Comparison',\n",
    " 'Comparison.Concession',\n",
    " 'Comparison.Concession.Contra-expectation',\n",
    " 'Comparison.Concession.Expectation',\n",
    " 'Comparison.Contrast',\n",
    " 'Comparison.Contrast.Juxtaposition',\n",
    " 'Comparison.Contrast.Opposition',\n",
    " 'Comparison.Pragmatic concession',\n",
    " 'Comparison.Pragmatic contrast',\n",
    " 'Contingency',\n",
    " 'Contingency.Cause',\n",
    " 'Contingency.Cause.Reason',\n",
    " 'Contingency.Cause.Result',\n",
    " 'Contingency.Condition.Hypothetical',\n",
    " 'Contingency.Pragmatic cause.Justification',\n",
    " 'Contingency.Pragmatic condition.Relevance',\n",
    " 'Expansion',\n",
    " 'Expansion.Alternative',\n",
    " 'Expansion.Alternative.Chosen alternative',\n",
    " 'Expansion.Alternative.Conjunctive',\n",
    " 'Expansion.Conjunction',\n",
    " 'Expansion.Exception',\n",
    " 'Expansion.Instantiation',\n",
    " 'Expansion.List',\n",
    " 'Expansion.Restatement',\n",
    " 'Expansion.Restatement.Equivalence',\n",
    " 'Expansion.Restatement.Generalization',\n",
    " 'Expansion.Restatement.Specification',\n",
    " 'Temporal',\n",
    " 'Temporal.Asynchronous.Precedence',\n",
    " 'Temporal.Asynchronous.Succession',\n",
    " 'Temporal.Synchrony']\n",
    "sense_pdtb3 = ['Comparison.Concession+SpeechAct.Arg2-as-denier+SpeechAct',\n",
    " 'Comparison.Concession.Arg1-as-denier',\n",
    " 'Comparison.Concession.Arg2-as-denier',\n",
    " 'Comparison.Contrast',\n",
    " 'Comparison.Similarity',\n",
    " 'Contingency.Cause+Belief.Reason+Belief',\n",
    " 'Contingency.Cause+Belief.Result+Belief',\n",
    " 'Contingency.Cause+SpeechAct.Reason+SpeechAct',\n",
    " 'Contingency.Cause+SpeechAct.Result+SpeechAct',\n",
    " 'Contingency.Cause.Reason',\n",
    " 'Contingency.Cause.Result',\n",
    " 'Contingency.Condition+SpeechAct',\n",
    " 'Contingency.Condition.Arg1-as-cond',\n",
    " 'Contingency.Condition.Arg2-as-cond',\n",
    " 'Contingency.Purpose.Arg1-as-goal',\n",
    " 'Contingency.Purpose.Arg2-as-goal',\n",
    " 'Expansion.Conjunction',\n",
    " 'Expansion.Disjunction',\n",
    " 'Expansion.Equivalence',\n",
    " 'Expansion.Exception.Arg1-as-excpt',\n",
    " 'Expansion.Exception.Arg2-as-excpt',\n",
    " 'Expansion.Instantiation.Arg1-as-instance',\n",
    " 'Expansion.Instantiation.Arg2-as-instance',\n",
    " 'Expansion.Level-of-detail.Arg1-as-detail',\n",
    " 'Expansion.Level-of-detail.Arg2-as-detail',\n",
    " 'Expansion.Manner.Arg1-as-manner',\n",
    " 'Expansion.Manner.Arg2-as-manner',\n",
    " 'Expansion.Substitution.Arg2-as-subst',\n",
    " 'Temporal.Asynchronous.Precedence',\n",
    " 'Temporal.Asynchronous.Succession',\n",
    " 'Temporal.Synchronous']\n",
    "sense_conll = ['Comparison',\n",
    " 'Comparison.Concession',\n",
    " 'Comparison.Contrast',\n",
    " 'Contingency',\n",
    " 'Contingency.Cause',\n",
    " 'Contingency.Cause.Reason',\n",
    " 'Contingency.Cause.Result',\n",
    " 'Contingency.Condition',\n",
    " 'Expansion',\n",
    " 'Expansion.Alternative',\n",
    " 'Expansion.Alternative.Chosen alternative',\n",
    " 'Expansion.Conjunction',\n",
    " 'Expansion.Exception',\n",
    " 'Expansion.Instantiation',\n",
    " 'Expansion.Restatement',\n",
    " 'Temporal',\n",
    " 'Temporal.Asynchronous.Precedence',\n",
    " 'Temporal.Asynchronous.Succession',\n",
    " 'Temporal.Synchrony']\n",
    "\n",
    "sense_dic = {\n",
    "    'pdtb2': sense_pdtb2,\n",
    "    'pdtb3': sense_pdtb3,\n",
    "    'conll': sense_conll,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sense_pdtb2\n",
    "sense_pdtb3\n",
    "sense_conll"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## level 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "order = 'Temporal Comparison Contingency Expansion'.split()\n",
    "order.sort()\n",
    "\n",
    "def sense_to_id(sense):\n",
    "    return order.index(sense.split('.')[0])\n",
    "\n",
    "label_map = {}\n",
    "for data_name, sense_list in sense_dic.items():\n",
    "    label_map[data_name] = {\n",
    "        sense:sense_to_id(sense)\n",
    "        for sense in sense_list\n",
    "    }\n",
    "json_path = r'D:\\0--data\\projects\\04.01-IDRR数据\\IDRR-base\\label_map\\level1.json'\n",
    "with open(json_path, 'w', encoding='utf8')as f:\n",
    "    json.dump(label_map, f, indent=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## level2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "\n",
    "label_map = {}\n",
    "for data_name, sense_list in sense_dic.items():\n",
    "    label_map[data_name] = {\n",
    "        sense:p\n",
    "        for p,sense in enumerate(sense_list)\n",
    "    }\n",
    "json_path = r'D:\\0--data\\projects\\04.01-IDRR数据\\IDRR-base\\label_map\\level2.json'\n",
    "with open(json_path, 'w', encoding='utf8')as f:\n",
    "    json.dump(label_map, f, indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sd = {'Concession':'Comparison','Contrast':'Comparison','Cause':'Contingency','Cause+Belief':'Contingency',\n",
    "                    'Condition':'Contingency','Purpose':'Contingency',\n",
    "                    'Conjunction':'Expansion','Equivalence':'Expansion','Instantiation':'Expansion','Level-of-detail':'Expansion',\n",
    "                    'Manner':'Expansion','Substitution':'Expansion',\n",
    "                    'Asynchronous':'Temporal','Synchronous':'Temporal',\n",
    "                    'None':'None'}\n",
    "len(sd)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python_main",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
