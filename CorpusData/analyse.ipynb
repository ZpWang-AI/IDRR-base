{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PDTB 2.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(16053, 10)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "usecols = [\n",
    "    'Relation', 'Section', \n",
    "    'Arg1_RawText', 'Arg2_RawText', \n",
    "    'Conn1', 'Conn2',\n",
    "    'ConnHeadSemClass1', 'ConnHeadSemClass2',\n",
    "    'Conn2SemClass1', 'Conn2SemClass2'\n",
    "]\n",
    "df = pd.read_csv(\n",
    "    r'D:\\0--data\\projects\\04.01-IDRR数据\\IDRR-base\\CorpusData\\PDTB2\\pdtb2.csv',\n",
    "    low_memory=False,\n",
    "    usecols=usecols,\n",
    ")\n",
    "# print(data.columns)\n",
    "\n",
    "# for k, v in data.iloc[0].to_dict().items():\n",
    "#     print(k, v)\n",
    "\n",
    "rename_map = {\n",
    "    'Arg1_RawText': 'Arg1',\n",
    "    'Arg2_RawText': 'Arg2',\n",
    "    'ConnHeadSemClass1': 'Conn1Sem1',\n",
    "    'ConnHeadSemClass2': 'Conn1Sem2',\n",
    "    'Conn2SemClass1': 'Conn2Sem1',\n",
    "    'Conn2SemClass2': 'Conn2Sem2',\n",
    "}\n",
    "df.rename(columns=rename_map, inplace=True)\n",
    "init_df = df.copy()\n",
    "\n",
    "df = df[df['Relation']=='Implicit']\n",
    "# print(df.shape)\n",
    "\n",
    "train_df = df[~df['Section'].isin([0, 1, 21, 22, 23, 24])]\n",
    "dev_df = df[df['Section'].isin([0, 1])]\n",
    "test_df = df[df['Section'].isin([21, 22])]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Comparison',\n",
       " 'Comparison.Concession',\n",
       " 'Comparison.Concession.Contra-expectation',\n",
       " 'Comparison.Concession.Expectation',\n",
       " 'Comparison.Contrast',\n",
       " 'Comparison.Contrast.Juxtaposition',\n",
       " 'Comparison.Contrast.Opposition',\n",
       " 'Comparison.Pragmatic concession',\n",
       " 'Comparison.Pragmatic contrast',\n",
       " 'Contingency',\n",
       " 'Contingency.Cause',\n",
       " 'Contingency.Cause.Reason',\n",
       " 'Contingency.Cause.Result',\n",
       " 'Contingency.Condition.Hypothetical',\n",
       " 'Contingency.Pragmatic cause.Justification',\n",
       " 'Contingency.Pragmatic condition.Relevance',\n",
       " 'Expansion',\n",
       " 'Expansion.Alternative',\n",
       " 'Expansion.Alternative.Chosen alternative',\n",
       " 'Expansion.Alternative.Conjunctive',\n",
       " 'Expansion.Conjunction',\n",
       " 'Expansion.Exception',\n",
       " 'Expansion.Instantiation',\n",
       " 'Expansion.List',\n",
       " 'Expansion.Restatement',\n",
       " 'Expansion.Restatement.Equivalence',\n",
       " 'Expansion.Restatement.Generalization',\n",
       " 'Expansion.Restatement.Specification',\n",
       " 'Temporal',\n",
       " 'Temporal.Asynchronous.Precedence',\n",
       " 'Temporal.Asynchronous.Succession',\n",
       " 'Temporal.Synchrony']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = df['Conn1Sem1'].unique().tolist()\n",
    "sorted(labels)\n",
    "# labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 一级多标签统计"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num of level1 labels\n",
      "{\n",
      "  \"Temporal\": {\n",
      "    \"\": 579,\n",
      "    \"Expansion\": 54,\n",
      "    \"Contingency\": 19,\n",
      "    \"Comparison\": 13,\n",
      "    \"Temporal\": 0\n",
      "  },\n",
      "  \"Comparison\": {\n",
      "    \"\": 1840,\n",
      "    \"Expansion\": 31,\n",
      "    \"Temporal\": 20,\n",
      "    \"Comparison\": 2,\n",
      "    \"Contingency\": 1\n",
      "  },\n",
      "  \"Contingency\": {\n",
      "    \"\": 3133,\n",
      "    \"Expansion\": 128,\n",
      "    \"Temporal\": 12,\n",
      "    \"Contingency\": 6,\n",
      "    \"Comparison\": 3\n",
      "  },\n",
      "  \"Expansion\": {\n",
      "    \"\": 6652,\n",
      "    \"Temporal\": 63,\n",
      "    \"Contingency\": 39,\n",
      "    \"Comparison\": 32,\n",
      "    \"Expansion\": 6\n",
      "  }\n",
      "}\n",
      "\n",
      "rank of level1 labels\n",
      "{\n",
      "  \"Temporal\": [\n",
      "    \"Comparison\",\n",
      "    \"Contingency\",\n",
      "    \"Expansion\"\n",
      "  ],\n",
      "  \"Comparison\": [\n",
      "    \"Contingency\",\n",
      "    \"Temporal\",\n",
      "    \"Expansion\"\n",
      "  ],\n",
      "  \"Contingency\": [\n",
      "    \"Comparison\",\n",
      "    \"Temporal\",\n",
      "    \"Expansion\"\n",
      "  ],\n",
      "  \"Expansion\": [\n",
      "    \"Comparison\",\n",
      "    \"Contingency\",\n",
      "    \"Temporal\"\n",
      "  ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "def sort_dict(dct):\n",
    "    return dict(sorted(dct.items(), key=lambda x:-x[1]))\n",
    "    \n",
    "class analyse_level1_label:\n",
    "    labels = 'Temporal Comparison Contingency Expansion'.split()\n",
    "    \n",
    "    @classmethod\n",
    "    def str_to_label(cls, string):\n",
    "        return string.split('.')[0]\n",
    "    \n",
    "    @classmethod\n",
    "    def get_item_labels(cls, item):\n",
    "        primary_label = cls.str_to_label(item.Conn1Sem1)\n",
    "        secondary_labels = []\n",
    "        for s in [item.Conn1Sem2, item.Conn2Sem1, item.Conn2Sem2]:\n",
    "            if not pd.isna(s):\n",
    "                secondary_labels.append(cls.str_to_label(s))\n",
    "        return primary_label, secondary_labels\n",
    "        \n",
    "    def __new__(cls, df, sort_res=True):\n",
    "        rec = {l:{ll:0 for ll in ['']+cls.labels}for l in cls.labels}\n",
    "        for p in range(df.shape[0]):\n",
    "            item = df.iloc[p]\n",
    "            primary_label, secondary_labels = cls.get_item_labels(item)\n",
    "            if not secondary_labels:\n",
    "                rec[primary_label][''] += 1\n",
    "            else:\n",
    "                for l in secondary_labels:\n",
    "                    rec[primary_label][l] += 1\n",
    "\n",
    "        if sort_res:\n",
    "            for k in rec:\n",
    "                rec[k] = sort_dict(rec[k])\n",
    "                \n",
    "        import json\n",
    "        rec_string = json.dumps(rec, ensure_ascii=False, indent=2)\n",
    "        print('num of level1 labels')\n",
    "        print(rec_string)\n",
    "        \n",
    "        rank = {}\n",
    "        for k in rec:\n",
    "            vals = sorted(cls.labels, key=lambda x:rec[k][x])\n",
    "            rank[k] = [v for v in vals if k != v]\n",
    "        rank_string = json.dumps(rank, ensure_ascii=False, indent=2)\n",
    "        print('\\nrank of level1 labels')\n",
    "        print(rank_string)\n",
    "        pass\n",
    "    \n",
    "\n",
    "analyse_level1_label(train_df)    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PDTB 3.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## preprocess: merge section to csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# prepare `sections` by `preprocess_pdtb3.py`\n",
    "fold_path = r'D:\\0--data\\projects\\04.01-IDRR数据\\IDRR-base\\CorpusData\\PDTB3\\data\\sections'\n",
    "\n",
    "columns = []\n",
    "data_list = []\n",
    "for p in range(25):\n",
    "    with open(os.path.join(fold_path, str(p).rjust(2,'0')+'.tsv'), 'r', encoding='utf8')as file:\n",
    "        content = list(file.readlines())\n",
    "        columns = content[0]\n",
    "        data_list.extend(content[1:])\n",
    "columns = columns.strip().split('\\t')\n",
    "data_list = [line.strip('\\n').split('\\t')for line in data_list if line.strip()]\n",
    "# print(set(map(len, data_list)))\n",
    "df = pd.DataFrame(data_list, columns=columns)\n",
    "columns\n",
    "df.shape\n",
    "df.to_csv(r'D:\\0--data\\projects\\04.01-IDRR数据\\IDRR-base\\CorpusData\\PDTB3\\pdtb3_implicit.csv', sep='\\t', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "for line in df['arg2']:\n",
    "    # if len(re.findall(r'\\d', line)) > 3:\n",
    "    #     print(line)\n",
    "    if 'wj_' in line:\n",
    "        print(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['',\n",
       " 'Comparison.Concession.Arg2-as-denier',\n",
       " 'Comparison.Contrast',\n",
       " 'Comparison.Similarity',\n",
       " 'Contingency.Cause+Belief.Reason+Belief',\n",
       " 'Contingency.Cause.Reason',\n",
       " 'Contingency.Cause.Result',\n",
       " 'Contingency.Purpose.Arg2-as-goal',\n",
       " 'Expansion.Conjunction',\n",
       " 'Expansion.Equivalence',\n",
       " 'Expansion.Instantiation.Arg2-as-instance',\n",
       " 'Expansion.Level-of-detail.Arg1-as-detail',\n",
       " 'Expansion.Level-of-detail.Arg2-as-detail',\n",
       " 'Expansion.Manner.Arg1-as-manner',\n",
       " 'Expansion.Manner.Arg2-as-manner',\n",
       " 'Expansion.Substitution.Arg2-as-subst',\n",
       " 'Temporal.Asynchronous.Precedence',\n",
       " 'Temporal.Asynchronous.Succession',\n",
       " 'Temporal.Synchronous']"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(set(df['conn2_sense1']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## other's preprocess (strange)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "idx                                                            0\n",
       "split                                                      train\n",
       "section                                                        2\n",
       "file_number                                             wsj_0200\n",
       "label                                                  Expansion\n",
       "category                                                Implicit\n",
       "arg1           In an Oct. 19 review of \"The Misanthrope\" at C...\n",
       "arg2                                     Ms. Haag plays Elianti.\n",
       "conn                                                     in fact\n",
       "full_sense              Expansion.Level-of-detail.Arg2-as-detail\n",
       "Name: 0, dtype: object"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# train.csv 9308\n",
    "# sections\\12.tsv 387\n",
    "\n",
    "train_file = r'D:\\0--data\\projects\\04.01-IDRR数据\\IDRR-base\\CorpusData\\PDTB3\\processed\\train.tsv'\n",
    "train_file = r'D:\\0--data\\projects\\04.01-IDRR数据\\IDRR-base\\tmp\\ttmp\\train.tsv'\n",
    "# df\n",
    "with open(train_file, 'r', encoding='utf8')as f:\n",
    "    content = list(f.readlines())\n",
    "    for p in range(9308, 9310):\n",
    "        # print(repr(content[p]))\n",
    "        # print(p, len(content[p].split('\\t')))\n",
    "        # for d in content[p].split('\\t'):\n",
    "        #     print(d)\n",
    "        pass\n",
    "fake_content = [content[0],content[1],content[9307],content[9308],content[9309]]\n",
    "# with open(r'D:\\0--data\\projects\\04.01-IDRR数据\\IDRR-base\\tmp\\fake.csv', 'w', encoding='utf8')as f:\n",
    "#     f.writelines(fake_content)\n",
    "# with open(r'D:\\0--data\\projects\\04.01-IDRR数据\\IDRR-base\\tmp\\fake.tsv', 'w', encoding='utf8')as f:\n",
    "#     f.writelines(fake_content)\n",
    "\n",
    "content = [line.strip().split('\\t')for line in content]\n",
    "# for p, line in enumerate(content):\n",
    "#     if len(line) != 10:\n",
    "#         print(p)\n",
    "# print(content[9308:9310])\n",
    "skiprows = [\n",
    "    9308,\n",
    "]\n",
    "df = pd.read_csv(train_file, sep='\\t'\n",
    "                 , skiprows=skiprows, encoding='latin1'\n",
    "                 )\n",
    "# df.columns\n",
    "df.iloc[0]\n",
    "# sorted(set(df['full_sense']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12\twsj_1250\tImplicit\tChina had refused to repatriate citizens who sneaked into Hong Kong illegally since early this month, when the colony allowed a dissident Chinese swimmer to flee to the U.S.\tAbout 1,100 Chinese were awaiting repatriation yesterday.\tin fact\tContingency.Cause.Result\t\t\t\t\n",
      "\n",
      "12\twsj_1250\tImplicit\tBut the Japanese Fisheries Association criticized moves to ban the practice in international waters.\t\"It is really unfortunate for human beings to be swayed by emotional discussions, the association said.\tspecifically\tExpansion.Level-of-detail.Arg2-as-detail\t\t\t\t\n",
      "\n",
      "12\twsj_1250\tImplicit\tWorkers at Peugeot S.A.'s car plant at Sochaux, in eastern France, voted to end a six-week-old strike that has cost the Peugeot group production of 60,000 automobiles,\tThe strikers voted to accept a series of management proposals that will give them a higher basic wage, better profit-sharing benefits and bigger annual bonuses.\tin particular\tExpansion.Level-of-detail.Arg2-as-detail\t\t\t\t\n",
      "\n",
      "     section  filename relation_type  \\\n",
      "385       12  wsj_1253      Implicit   \n",
      "386       12  wsj_1253      Implicit   \n",
      "387       12  wsj_1253      Implicit   \n",
      "\n",
      "                                                  arg1  \\\n",
      "385  One of Mr. Roberts's observations is that the ...   \n",
      "386                               This is just not so.   \n",
      "387  The reality is that Bank finances are rock solid.   \n",
      "\n",
      "                                                  arg2        conn1  \\\n",
      "385                               This is just not so.      however   \n",
      "386  The reality is that Bank finances are rock solid.      instead   \n",
      "387  As of June 30, 1989 -- the day our past fiscal...  for example   \n",
      "\n",
      "                                 conn1_sense1  conn1_sense2 conn2  \\\n",
      "385      Comparison.Concession.Arg2-as-denier           NaN   NaN   \n",
      "386      Expansion.Substitution.Arg2-as-subst           NaN   NaN   \n",
      "387  Expansion.Instantiation.Arg2-as-instance           NaN   NaN   \n",
      "\n",
      "    conn2_sense1  conn2_sense2  \n",
      "385          NaN           NaN  \n",
      "386          NaN           NaN  \n",
      "387          NaN           NaN  \n",
      "991 (979, 11)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "strange_file = r'D:\\0--data\\projects\\04.01-IDRR数据\\IDRR-base\\CorpusData\\PDTB3\\data\\sections\\12.tsv'\n",
    "cur_pd12 = pd.read_csv(strange_file, delimiter='\\t', skiprows=[386])\n",
    "\n",
    "with open(strange_file, 'r', encoding='utf8')as file:\n",
    "    content = list(file.readlines())\n",
    "print(content[385])\n",
    "print(content[386])\n",
    "print(content[387])\n",
    "print(cur_pd12.iloc[385:388])\n",
    "print(len(content), cur_pd12.shape)\n",
    "# print(cur_pd12.iloc[386])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['section', 'filename', 'relation_type', 'arg1', 'arg2', 'conn1',\n",
       "       'conn1_sense1', 'conn1_sense2', 'conn2', 'conn2_sense1',\n",
       "       'conn2_sense2'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(r'D:\\0--data\\projects\\04.01-IDRR数据\\IDRR-base\\CorpusData\\PDTB3\\pdtb3_implicit.csv', delimiter='\\t')\n",
    "df.columns\n",
    "# df.iloc[9305:9310]\n",
    "# df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CoNLL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Arg1': {'CharacterSpanList': [[9, 240]],\n",
       "  'RawText': 'In an Oct. 19 review of \"The Misanthrope\" at Chicago\\'s Goodman Theatre (\"Revitalized Classics Take the Stage in Windy City,\" Leisure & Arts), the role of Celimene, played by Kim Cattrall, was mistakenly attributed to Christina Haag',\n",
       "  'TokenList': [[9, 11, 0, 0, 0],\n",
       "   [12, 14, 1, 0, 1],\n",
       "   [15, 19, 2, 0, 2],\n",
       "   [20, 22, 3, 0, 3],\n",
       "   [23, 29, 4, 0, 4],\n",
       "   [30, 32, 5, 0, 5],\n",
       "   [33, 34, 6, 0, 6],\n",
       "   [34, 37, 7, 0, 7],\n",
       "   [38, 49, 8, 0, 8],\n",
       "   [49, 50, 9, 0, 9],\n",
       "   [51, 53, 10, 0, 10],\n",
       "   [54, 61, 11, 0, 11],\n",
       "   [61, 63, 12, 0, 12],\n",
       "   [64, 71, 13, 0, 13],\n",
       "   [72, 79, 14, 0, 14],\n",
       "   [80, 81, 15, 0, 15],\n",
       "   [81, 82, 16, 0, 16],\n",
       "   [82, 93, 17, 0, 17],\n",
       "   [94, 102, 18, 0, 18],\n",
       "   [103, 107, 19, 0, 19],\n",
       "   [108, 111, 20, 0, 20],\n",
       "   [112, 117, 21, 0, 21],\n",
       "   [118, 120, 22, 0, 22],\n",
       "   [121, 126, 23, 0, 23],\n",
       "   [127, 131, 24, 0, 24],\n",
       "   [131, 132, 25, 0, 25],\n",
       "   [132, 133, 26, 0, 26],\n",
       "   [134, 141, 27, 0, 27],\n",
       "   [142, 143, 28, 0, 28],\n",
       "   [144, 148, 29, 0, 29],\n",
       "   [148, 149, 30, 0, 30],\n",
       "   [149, 150, 31, 0, 31],\n",
       "   [151, 154, 32, 0, 32],\n",
       "   [155, 159, 33, 0, 33],\n",
       "   [160, 162, 34, 0, 34],\n",
       "   [163, 171, 35, 0, 35],\n",
       "   [171, 172, 36, 0, 36],\n",
       "   [173, 179, 37, 0, 37],\n",
       "   [180, 182, 38, 0, 38],\n",
       "   [183, 186, 39, 0, 39],\n",
       "   [187, 195, 40, 0, 40],\n",
       "   [195, 196, 41, 0, 41],\n",
       "   [197, 200, 42, 0, 42],\n",
       "   [201, 211, 43, 0, 43],\n",
       "   [212, 222, 44, 0, 44],\n",
       "   [223, 225, 45, 0, 45],\n",
       "   [226, 235, 46, 0, 46],\n",
       "   [236, 240, 47, 0, 47]]},\n",
       " 'Arg2': {'CharacterSpanList': [[242, 264]],\n",
       "  'RawText': 'Ms. Haag plays Elianti',\n",
       "  'TokenList': [[242, 245, 49, 1, 0],\n",
       "   [246, 250, 50, 1, 1],\n",
       "   [251, 256, 51, 1, 2],\n",
       "   [257, 264, 52, 1, 3]]},\n",
       " 'Connective': {'CharacterSpanList': [],\n",
       "  'RawText': 'however',\n",
       "  'TokenList': []},\n",
       " 'DocID': 'wsj_0200',\n",
       " 'ID': 3173,\n",
       " 'Sense': ['Comparison.Contrast'],\n",
       " 'Type': 'Implicit'}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "train_file = r'D:\\0--data\\projects\\04.01-IDRR数据\\IDRR-base\\CorpusData\\2015-2016_conll_shared_task\\data\\conll16st-en-03-29-16-train\\relations.json'\n",
    "dev_file = r'D:\\0--data\\projects\\04.01-IDRR数据\\IDRR-base\\CorpusData\\2015-2016_conll_shared_task\\data\\conll16st-en-03-29-16-dev\\relations.json'\n",
    "test_file = r'D:\\0--data\\projects\\04.01-IDRR数据\\IDRR-base\\CorpusData\\2015-2016_conll_shared_task\\data\\conll16st-en-03-29-16-test\\relations.json'\n",
    "blind_test_file = r'D:\\0--data\\projects\\04.01-IDRR数据\\IDRR-base\\CorpusData\\2015-2016_conll_shared_task\\data\\conll16st-en-03-29-16-blind-test\\relations.json'\n",
    "\n",
    "def get_dicts(file):\n",
    "    # dicts = []\n",
    "    with open(file, 'r', encoding='utf8')as f:\n",
    "        dicts = [json.loads(line)for line in f.readlines()]\n",
    "    return dicts\n",
    "\n",
    "train_dicts = get_dicts(train_file)\n",
    "train_dicts = [p for p in train_dicts if p['Type'] == 'Implicit']\n",
    "sample = train_dicts[0]\n",
    "sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Comparison',\n",
       " 'Comparison.Concession',\n",
       " 'Comparison.Contrast',\n",
       " 'Contingency',\n",
       " 'Contingency.Cause',\n",
       " 'Contingency.Cause.Reason',\n",
       " 'Contingency.Cause.Result',\n",
       " 'Contingency.Condition',\n",
       " 'Expansion',\n",
       " 'Expansion.Alternative',\n",
       " 'Expansion.Alternative.Chosen alternative',\n",
       " 'Expansion.Conjunction',\n",
       " 'Expansion.Exception',\n",
       " 'Expansion.Instantiation',\n",
       " 'Expansion.Restatement',\n",
       " 'Temporal',\n",
       " 'Temporal.Asynchronous.Precedence',\n",
       " 'Temporal.Asynchronous.Succession',\n",
       " 'Temporal.Synchrony']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "total_senses = [q for p in train_dicts for q in p['Sense']]\n",
    "sorted(set(total_senses))\n",
    "\n",
    "# senses_cnt = Counter('&'.join(p['Sense'])for p in train_dicts)\n",
    "# senses_cnt = dict(sorted(senses_cnt.items()))\n",
    "# senses_cnt\n",
    "\n",
    "# Counter(len(p['Sense'])for p in train_dicts)\n",
    "\n",
    "# Counter(p['Type']for p in train_dicts)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python_main",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
